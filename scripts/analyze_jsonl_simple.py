#!/usr/bin/env python3
"""
Godzilla JSONL Dataset Analysis (No Dependencies)
Provides detailed statistics using only built-in Python modules
"""

import json
from collections import Counter, defaultdict

def analyze_jsonl_dataset(jsonl_file_path):
    """Analyze the JSONL dataset using only built-in modules"""
    
    print("ü¶ñ GODZILLA MEDICAL DATASET - JSONL ANALYSIS")
    print("=" * 80)
    
    # Load and analyze records
    records = []
    source_counts = Counter()
    specialty_counts = Counter()
    training_cats = Counter()
    difficulty_counts = Counter()
    age_group_counts = Counter()
    source_file_counts = Counter()
    confidence_scores = []
    text_lengths = []
    word_counts = []
    all_keywords = []
    
    with open(jsonl_file_path, 'r', encoding='utf-8') as f:
        for line in f:
            record = json.loads(line.strip())
            records.append(record)
            
            # Collect statistics
            source_counts[record.get('source_dataset', 'unknown')] += 1
            specialty_counts[record.get('medical_specialty', 'unknown')] += 1
            training_cats[record.get('training_category', 'unknown')] += 1
            difficulty_counts[record.get('reading_difficulty', 'unknown')] += 1
            age_group_counts[record.get('age_groups', 'unknown')] += 1
            source_file_counts[record.get('source_file', 'unknown')] += 1
            
            # Numerical values
            confidence_scores.append(float(record.get('confidence_score', 0)))
            text_lengths.append(int(record.get('text_length', 0)))
            word_counts.append(int(record.get('word_count_calculated', 0)))
            
            # Keywords
            keywords = record.get('keywords', [])
            if isinstance(keywords, list):
                all_keywords.extend(keywords)
    
    total_records = len(records)
    
    print(f"üìä DATASET OVERVIEW")
    print(f"   Total Records: {total_records:,}")
    print(f"   Average Text Length: {sum(text_lengths)//len(text_lengths):,} characters")
    print(f"   Average Word Count: {sum(word_counts)//len(word_counts):,} words")
    
    print(f"\nüìã SOURCE DISTRIBUTION")
    for source, count in source_counts.most_common():
        percentage = (count / total_records) * 100
        print(f"   {source}: {count:,} records ({percentage:.1f}%)")
    
    print(f"\nüè• MEDICAL SPECIALTIES (Top 15)")
    for specialty, count in specialty_counts.most_common(15):
        percentage = (count / total_records) * 100
        print(f"   {specialty}: {count:,} records ({percentage:.1f}%)")
    
    print(f"\nüìà QUALITY METRICS")
    avg_confidence = sum(confidence_scores) / len(confidence_scores)
    min_confidence = min(confidence_scores)
    max_confidence = max(confidence_scores)
    high_quality = sum(1 for score in confidence_scores if score >= 0.8)
    
    print(f"   Average Confidence: {avg_confidence:.3f}")
    print(f"   Min Confidence: {min_confidence:.3f}")
    print(f"   Max Confidence: {max_confidence:.3f}")
    print(f"   High Quality (‚â•0.8): {high_quality:,} ({high_quality/total_records*100:.1f}%)")
    
    print(f"\nüìù TEXT LENGTH DISTRIBUTION")
    short_texts = sum(1 for length in text_lengths if length < 1000)
    medium_texts = sum(1 for length in text_lengths if 1000 <= length < 3000)
    long_texts = sum(1 for length in text_lengths if length >= 3000)
    
    print(f"   Short texts (<1K chars): {short_texts:,} ({short_texts/total_records*100:.1f}%)")
    print(f"   Medium texts (1K-3K chars): {medium_texts:,} ({medium_texts/total_records*100:.1f}%)")
    print(f"   Long texts (‚â•3K chars): {long_texts:,} ({long_texts/total_records*100:.1f}%)")
    
    print(f"\nüéØ TRAINING CATEGORIES")
    for category, count in training_cats.most_common(10):
        percentage = (count / total_records) * 100
        print(f"   {category}: {count:,} records ({percentage:.1f}%)")
    
    print(f"\nüìö READING DIFFICULTY")
    for difficulty, count in difficulty_counts.most_common():
        percentage = (count / total_records) * 100
        print(f"   {difficulty}: {count:,} records ({percentage:.1f}%)")
    
    print(f"\nüë• AGE GROUPS")
    for age_group, count in age_group_counts.most_common():
        percentage = (count / total_records) * 100
        print(f"   {age_group}: {count:,} records ({percentage:.1f}%)")
    
    print(f"\nüîç TOP KEYWORDS")
    keyword_counts = Counter(all_keywords)
    print(f"   Total Unique Keywords: {len(keyword_counts):,}")
    print(f"   Total Keyword Occurrences: {len(all_keywords):,}")
    print(f"   Top 20 Keywords:")
    for keyword, count in keyword_counts.most_common(20):
        print(f"     '{keyword}': {count:,} occurrences")
    
    print(f"\nüìñ SOURCE FILES (Top 12)")
    for source_file, count in source_file_counts.most_common(12):
        percentage = (count / total_records) * 100
        print(f"   {source_file}: {count:,} records ({percentage:.1f}%)")
    
    print(f"\n‚≠ê ML TRAINING RECOMMENDATIONS")
    print(f"   üéØ Use confidence_score ‚â• 0.8 for high-quality training ({high_quality:,} records)")
    print(f"   üè• Filter by medical_specialty for specialized models")
    print(f"   üî§ Use keywords array for multi-label classification ({len(keyword_counts):,} unique tags)")
    print(f"   üìè Consider text_length for batch sizing (avg: {sum(text_lengths)//len(text_lengths):,} chars)")
    print(f"   üë∂ Pediatrics dominance ({specialty_counts['pediatrics']:,} records) - ideal for pediatric AI")
    print(f"   üìö Expert-level content - suitable for medical professional training")
    
    print(f"\nüîß SUGGESTED TRAINING SPLITS")
    train_size = int(total_records * 0.8)
    val_size = int(total_records * 0.1)
    test_size = total_records - train_size - val_size
    print(f"   Training: {train_size:,} records (80%)")
    print(f"   Validation: {val_size:,} records (10%)")
    print(f"   Testing: {test_size:,} records (10%)")
    
    print(f"\nüì¶ DATASET FORMATS READY FOR")
    print(f"   ‚Ä¢ Hugging Face Datasets")
    print(f"   ‚Ä¢ OpenAI Fine-tuning")
    print(f"   ‚Ä¢ RAG System Vector Store")
    print(f"   ‚Ä¢ Medical Question Answering")
    print(f"   ‚Ä¢ Text Classification")
    print(f"   ‚Ä¢ Named Entity Recognition")
    
    return records

if __name__ == "__main__":
    # Analyze the JSONL dataset
    jsonl_file = "/project/workspace/godzilla_medical_dataset.jsonl"
    records = analyze_jsonl_dataset(jsonl_file)
    
    print(f"\nü¶ñ Analysis complete! Your Godzilla dataset is ready to dominate medical AI!")
    print(f"üìä {len(records):,} high-quality medical records converted to JSONL format.")